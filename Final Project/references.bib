@INPROCEEDINGS{6309553,
  author={Nieuwenhuisen, Matthias and Stueckler, Joerg and Berner, Alexander and Klein, Reinhard and Behnke, Sven},
  booktitle={ROBOTIK 2012; 7th German Conference on Robotics}, 
  title={Shape-Primitive Based Object Recognition and Grasping}, 
  year={2012},
  volume={},
  number={},
  pages={1-5},
  doi={}}


@INPROCEEDINGS{5764019,
  author={Jun Chu and Chun-mei Nie},
  booktitle={2011 3rd International Conference on Computer Research and Development}, 
  title={Multi-view point clouds registration and stitching based on SIFT feature}, 
  year={2011},
  volume={1},
  number={},
  pages={274-278},
  doi={10.1109/ICCRD.2011.5764019}}

@inproceedings{inproceedings,
author = {Papazov, Chavdar and Burschka, Darius},
year = {2010},
month = {01},
pages = {135-148},
title = {An Efficient RANSAC for 3D Object Recognition in Noisy and Occluded Scenes.},
doi = {10.13140/2.1.1451.1041}
}

@Article{rs14092110,
AUTHOR = {Wang, Bingxu and Lan, Jinhui and Gao, Jiangjiang},
TITLE = {LiDAR Filtering in 3D Object Detection Based on Improved RANSAC},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {9},
ARTICLE-NUMBER = {2110},
URL = {https://www.mdpi.com/2072-4292/14/9/2110},
ISSN = {2072-4292},
ABSTRACT = {At present, the LiDAR ground filtering technology is very mature. There are fewer applications in 3D-object detection due to the limitations of filtering accuracy and efficiency. If the ground can be removed quickly and accurately, the 3D-object detection algorithm can detect objects more accurately and quickly. In order to meet the application requirements of 3D-object detection, inspired by Universal-RANSAC, we analyze the detailed steps of RANSAC and propose a precise and efficient RANSAC-based ground filtering method. The principle of GroupSAC is analyzed, and the sampled points are grouped by attributes to make it easier to sample the correct point. Based on this principle, we devise a method for limiting sampled points that is applicable to point clouds. We describe preemptive RANSAC in detail. Its breadth-first strategy is adopted to obtain the optimal plane without complex iterations. We use the International Society for Photogrammetry and Remote Sensing (ISPRS) datasets and the KITTI dataset for testing. Experiments show that our method has higher filtering accuracy and efficiency compared with the currently widely used methods. We explore the application of ground filtering methods in 3D-object detection, and the experimental results show that our method can improve the object detection accuracy without affecting the efficiency.},
DOI = {10.3390/rs14092110}
}


@INPROCEEDINGS{6739623,
  author={Yu, Jincheng and Weng, Kaijian and Liang, Guoyuan and Xie, Guanghan},
  booktitle={2013 IEEE International Conference on Robotics and Biomimetics (ROBIO)}, 
  title={A vision-based robotic grasping system using deep learning for 3D object recognition and pose estimation}, 
  year={2013},
  volume={},
  number={},
  pages={1175-1180},
  doi={10.1109/ROBIO.2013.6739623}
}

@misc{frankaemika, 
    title={Frankaemika/FRANKA_ROS: Ros Integration for Franka Emika Research Robots}, 
    url={https://github.com/frankaemika/franka_ros}, 
    journal={GitHub}, 
    author={Frankaemika}
} 

@misc{intel, title={Intel® RealSense™ Technology}, 
    url={https://www.intel.com/content/www/us/en/architecture-and-technology/realsense-overview.html}, 
    journal={Intel}
} 

@misc{brand, 
    title={MoveIt!}, 
    url={https://moveit.ros.org/}, 
    journal={Brand}
}

 @book{the stanford 3d scanning repository, 
    title={The Stanford Bunny}, 
    url={http://graphics.stanford.edu/data/3Dscanrep}, 
    journal={The Stanford 3D Scanning Repository}
 } 

@article{https://doi.org/10.1111/j.1467-8659.2007.01016.x,
author = {Schnabel, R. and Wahl, R. and Klein, R.},
title = {Efficient RANSAC for Point-Cloud Shape Detection},
journal = {Computer Graphics Forum},
volume = {26},
number = {2},
pages = {214-226},
keywords = {large point-clouds, geometry analysis, shape fitting, localized RANSAC, primitive shapes, I.4.8: Scene Analysis Shape; Surface Fitting, I.3.5: Computational Geometry and Object Modeling Curve, surface, solid, object representations},
doi = {https://doi.org/10.1111/j.1467-8659.2007.01016.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2007.01016.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2007.01016.x},
abstract = {Abstract In this paper we present an automatic algorithm to detect basic shapes in unorganized point clouds. The algorithm decomposes the point cloud into a concise, hybrid structure of inherent shapes and a set of remaining points. Each detected shape serves as a proxy for a set of corresponding points. Our method is based on random sampling and detects planes, spheres, cylinders, cones and tori. For models with surfaces composed of these basic shapes only, for example, CAD models, we automatically obtain a representation solely consisting of shape proxies. We demonstrate that the algorithm is robust even in the presence of many outliers and a high degree of noise. The proposed method scales well with respect to the size of the input point cloud and the number and size of the shapes within the data. Even point sets with several millions of samples are robustly decomposed within less than a minute. Moreover, the algorithm is conceptually simple and easy to implement. Application areas include measurement of physical parameters, scan registration, surface compression, hybrid rendering, shape classification, meshing, simplification, approximation and reverse engineering.},
year = {2007}
}

@INPROCEEDINGS{1211449,
  author={Gotardo, P.F.U. and Bellon, O.R.P. and Silva, L.},
  booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.}, 
  title={Range image segmentation by surface extraction using an improved robust estimator}, 
  year={2003},
  volume={2},
  number={},
  pages={II-33},
  doi={10.1109/CVPR.2003.1211449}
}

@article{ROTH19931,
title = {Extracting Geometric Primitives},
journal = {CVGIP: Image Understanding},
volume = {58},
number = {1},
pages = {1-22},
year = {1993},
issn = {1049-9660},
doi = {https://doi.org/10.1006/ciun.1993.1028},
url = {https://www.sciencedirect.com/science/article/pii/S1049966083710284},
author = {G. Roth and M.D. Levine},
abstract = {Extracting geometric primitives is an important task in model-based computer vision. The Hough transform is the most common method of extracting geometric primitives. Recently, methods derived from the field of robust statistics have been used for this purpose. We show that extracting a single geometric primitive is equivalent to finding the optimum value of a cost function which has potentially many local minima. Besides providing a unifying way of understanding different primitive extraction algorithms, this model also shows that for efficient extraction the true global minimum must be found with as few evaluations of the cost function as possible. In order to extract a single geometric primitive we choose a number of minimal subsets randomly from the geometric data. The cost function is evaluated for each of these, and the primitive defined by the subset with the best value of the cost function is extracted from the geometric data. To extract multiple primitives, this process is repeated on the geometric data that do not belong to the primitive. The resulting extraction algorithm can be used with a wide variety of geometric primitives and geometric data. It is easily parallelized, and we describe some possible implementations on a variety of parallel architectures. We make a detailed comparison with the Hough transform and show that it has a number of advantages over this classic technique.}
}

@ARTICLE{10.3389/frobt.2021.696587,
  
AUTHOR={Natarajan, Sabhari and Brown, Galen and Calli, Berk},   
TITLE={Aiding Grasp Synthesis for Novel Objects Using Heuristic-Based and Data-Driven Active Vision Methods},     	
JOURNAL={Frontiers in Robotics and AI},      
VOLUME={8},           
YEAR={2021},      
URL={https://www.frontiersin.org/articles/10.3389/frobt.2021.696587},       
DOI={10.3389/frobt.2021.696587},      
ISSN={2296-9144},   
ABSTRACT={In this work, we present several heuristic-based and data-driven active vision strategies for viewpoint optimization of an arm-mounted depth camera to aid robotic grasping. These strategies aim to efficiently collect data to boost the performance of an underlying grasp synthesis algorithm. We created an open-source benchmarking platform in simulation (<ext-link ext-link-type="uri" xlink:href="https://github.com/galenbr/2021ActiveVision" xmlns:xlink="http://www.w3.org/1999/xlink">https://github.com/galenbr/2021ActiveVision</ext-link>), and provide an extensive study for assessing the performance of the proposed methods as well as comparing them against various baseline strategies. We also provide an experimental study with a real-world two finger parallel jaw gripper setup by utilizing an existing grasp planning benchmark in the literature. With these analyses, we were able to quantitatively demonstrate the versatility of heuristic methods that prioritize certain types of exploration, and qualitatively show their robustness to both novel objects and the transition from simulation to the real world. We identified scenarios in which our methods did not perform well and objectively difficult scenarios, and present a discussion on which avenues for future research show promise.}
}

@InProceedings{Feng_2018_CVPR,
author = {Feng, Yifan and Zhang, Zizhao and Zhao, Xibin and Ji, Rongrong and Gao, Yue},
title = {GVCNN: Group-View Convolutional Neural Networks for 3D Shape Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@misc{methyldragon, 
    title={PCL-Ros-tutorial/PCL reference with ros.md at master · methylDragon/PCL-ros-tutorial}, 
    url={https://github.com/methylDragon/pcl-ros-tutorial/blob/master/PCL%20Reference%20with%20ROS.md}, 
    journal={GitHub}, 
    author={methylDragon}
} 